{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Classification - 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOregpQZxdix5BNPOFgf6fn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Volscente/image_classification/blob/main/Binary_Classification_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT-muVA0inoW"
      },
      "source": [
        "# Introduction\n",
        "This notebook is intended to demonstrate how to use TensorFlow for image classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8weqRStBiSCP"
      },
      "source": [
        "# Import Standard Modules\n",
        "import tensorflow\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdR7KKpRm6_I"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCPqfSl_m6Et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df378951-7884-4f23-8989-977ac297cb71"
      },
      "source": [
        "# Training Set\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n",
        "    -O ./horse-or-human.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-28 10:18:23--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.112, 172.217.164.144, 172.217.0.48, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘./horse-or-human.zip’\n",
            "\n",
            "./horse-or-human.zi 100%[===================>] 142.65M  54.5MB/s    in 2.6s    \n",
            "\n",
            "2021-10-28 10:18:25 (54.5 MB/s) - ‘./horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04wGrnJpnYa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece087b3-65f4-494d-9746-d016713c385c"
      },
      "source": [
        "# Validation Set\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n",
        "    -O ./validation-horse-or-human.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-28 10:18:26--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.122.128, 142.250.73.208, 172.253.63.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.122.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘./validation-horse-or-human.zip’\n",
            "\n",
            "./validation-horse- 100%[===================>]  10.95M  68.5MB/s    in 0.2s    \n",
            "\n",
            "2021-10-28 10:18:26 (68.5 MB/s) - ‘./validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsJbsQmunbAA"
      },
      "source": [
        "# Extract Training Set\n",
        "training_file = './horse-or-human.zip'\n",
        "training_file_ref = zipfile.ZipFile(training_file, 'r')\n",
        "training_file_ref.extractall('./training_horse-or-human')\n",
        "training_path = './training_horse-or-human'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm9KSeNasu6P"
      },
      "source": [
        "# Extract Validation Set\n",
        "validation_file = './validation-horse-or-human.zip'\n",
        "validation_file_ref = zipfile.ZipFile(validation_file, 'r')\n",
        "validation_file_ref.extractall('./validation_horse-or-human')\n",
        "validation_path = './validation_horse-or-human'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d5ny--Na58g"
      },
      "source": [
        "# Setup Paths\n",
        "training_humans = os.path.join(training_path, 'humans')\n",
        "training_horses = os.path.join(training_path, 'horses')\n",
        "validation_humans = os.path.join(validation_path, 'humans')\n",
        "validation_horses = os.path.join(validation_path, 'horses')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf0jOM3TdHwc"
      },
      "source": [
        "# Retrieve file names\n",
        "training_humans_files = os.listdir(training_humans)\n",
        "training_horses_files = os.listdir(training_horses)\n",
        "validation_humans_files = os.listdir(validation_humans)\n",
        "validation_horses_files = os.listdir(validation_horses)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VjBuAeStYFO",
        "outputId": "07ee433c-87cf-4b21-d35d-7a74e12bb8ff"
      },
      "source": [
        "# Inspect the Training and Validation Sets\n",
        "print(\"Training Set - Human Image: {}\".format(len(os.listdir(training_humans))))\n",
        "print(\"Training Set - Horses Image: {}\".format(len(os.listdir(training_horses))))\n",
        "print(\"Validation Set - Human Image: {}\".format(len(os.listdir(validation_humans))))\n",
        "print(\"Validation Set - Horses Image: {}\".format(len(os.listdir(validation_horses))))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set - Human Image: 527\n",
            "Training Set - Horses Image: 500\n",
            "Validation Set - Human Image: 128\n",
            "Validation Set - Horses Image: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3sXIkBPtKYn"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGYZSMG2tN1X"
      },
      "source": [
        "# Get current matplotlib figure\n",
        "figure = plt.gcf()\n",
        "\n",
        "# Setup figure size\n",
        "figure.set_size_inches(4, 4)\n",
        "\n",
        "# Number of desired sample images\n",
        "sample_images = 4\n",
        "\n",
        "# Retrieve sample training humans images\n",
        "sample_training_humans_images = [os.path.join(training_humans, filename) for filename in ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o4SnaaYr3PL"
      },
      "source": [
        "# Data Preparation\n",
        "Prepare the images through ImageDataGenerator from TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ZR5YYetQ_R"
      },
      "source": [
        "# Define the ImageDataGenerator for the Training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    rotation_range=40, \n",
        "    width_shift_range=0.2, \n",
        "    height_shift_range=0.2, \n",
        "    shear_range=0.2, \n",
        "    zoom_range=0.2, \n",
        "    horizontal_flip=True, \n",
        "    fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPbtn3zSSSbT"
      },
      "source": [
        "# Define the ImageDataGenerator for the Validation Set\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3OwVkhbSZyw",
        "outputId": "d31b79f1-a133-4a4e-f061-1bfd318ab0f9"
      },
      "source": [
        "# Define the Training Generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory='/content/training_horse-or-human/', \n",
        "    target_size=(300, 300), \n",
        "    batch_size=128, \n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9GnGBPeTfnb",
        "outputId": "a1c919fc-aabc-4b9a-d5ba-ff88c942c871"
      },
      "source": [
        "# Define the Validation Generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    directory='/content/validation_horse-or-human/', \n",
        "    target_size=(300, 300), \n",
        "    class_mode='binary', \n",
        "    batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdNGTrAAXfKb"
      },
      "source": [
        "# Neural Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr6PRes_X1BC"
      },
      "source": [
        "# Define the Neural Network Structure\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(300, 300, 3))                                       \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}