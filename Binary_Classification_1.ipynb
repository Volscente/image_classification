{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Classification - 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPUdbHV4DJ3twPDdHSw0dGz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Volscente/image_classification/blob/main/Binary_Classification_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT-muVA0inoW"
      },
      "source": [
        "# Introduction\n",
        "This notebook is intended to demonstrate how to use TensorFlow for image classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8weqRStBiSCP"
      },
      "source": [
        "# Import Standard Modules\n",
        "import tensorflow\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdR7KKpRm6_I"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCPqfSl_m6Et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efc47ba-0d06-4405-a4f0-81daadea78b2"
      },
      "source": [
        "# Training Set\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n",
        "    -O ./horse-or-human.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-21 14:26:14--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 74.125.204.128, 64.233.189.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘./horse-or-human.zip’\n",
            "\n",
            "./horse-or-human.zi 100%[===================>] 142.65M  68.2MB/s    in 2.1s    \n",
            "\n",
            "2021-10-21 14:26:17 (68.2 MB/s) - ‘./horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04wGrnJpnYa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1b7444-ddb5-4fe3-9df6-2a01acb1f20e"
      },
      "source": [
        "# Validation Set\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n",
        "    -O ./validation-horse-or-human.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-21 14:26:17--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.125.128, 74.125.23.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘./validation-horse-or-human.zip’\n",
            "\n",
            "./validation-horse- 100%[===================>]  10.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-10-21 14:26:18 (136 MB/s) - ‘./validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsJbsQmunbAA"
      },
      "source": [
        "# Extract Training Set\n",
        "training_file = './horse-or-human.zip'\n",
        "training_file_ref = zipfile.ZipFile(training_file, 'r')\n",
        "training_file_ref.extractall('./training_horse-or-human')\n",
        "training_path = './training_horse-or-human'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm9KSeNasu6P"
      },
      "source": [
        "# Extract Validation Set\n",
        "validation_file = './validation-horse-or-human.zip'\n",
        "validation_file_ref = zipfile.ZipFile(validation_file, 'r')\n",
        "validation_file_ref.extractall('./validation_horse-or-human')\n",
        "validation_path = './validation_horse-or-human'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VjBuAeStYFO",
        "outputId": "09eb8e04-7aff-42b2-c0d8-09a940e18db2"
      },
      "source": [
        "# Inspect the Training and Validation Sets\n",
        "print(\"Training Set - Human Image: {}\".format(len(os.listdir(training_path + '/humans'))))\n",
        "print(\"Training Set - Horses Image: {}\".format(len(os.listdir(training_path + '/horses'))))\n",
        "print(\"Validation Set - Human Image: {}\".format(len(os.listdir(validation_path + '/humans'))))\n",
        "print(\"Validation Set - Horses Image: {}\".format(len(os.listdir(validation_path + '/horses'))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set - Human Image: 527\n",
            "Training Set - Horses Image: 500\n",
            "Validation Set - Human Image: 128\n",
            "Validation Set - Horses Image: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3sXIkBPtKYn"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGYZSMG2tN1X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o4SnaaYr3PL"
      },
      "source": [
        "# Data Preparation\n",
        "Prepare the images through ImageDataGenerator from TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ZR5YYetQ_R"
      },
      "source": [
        "# Define the ImageDataGenerator for the Training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    rotation_range=40, \n",
        "    width_shift_range=0.2, \n",
        "    height_shift_range=0.2, \n",
        "    shear_range=0.2, \n",
        "    zoom_range=0.2, \n",
        "    horizontal_flip=True, \n",
        "    fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPbtn3zSSSbT"
      },
      "source": [
        "# Define the ImageDataGenerator for the Validation Set\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3OwVkhbSZyw",
        "outputId": "d31b79f1-a133-4a4e-f061-1bfd318ab0f9"
      },
      "source": [
        "# Define the Training Generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory='/content/training_horse-or-human/', \n",
        "    target_size=(300, 300), \n",
        "    batch_size=128, \n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9GnGBPeTfnb",
        "outputId": "a1c919fc-aabc-4b9a-d5ba-ff88c942c871"
      },
      "source": [
        "# Define the Validation Generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    directory='/content/validation_horse-or-human/', \n",
        "    target_size=(300, 300), \n",
        "    class_mode='binary', \n",
        "    batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdNGTrAAXfKb"
      },
      "source": [
        "# Neural Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr6PRes_X1BC"
      },
      "source": [
        "# Define the Neural Network Structure\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(300, 300, 3))                                       \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}